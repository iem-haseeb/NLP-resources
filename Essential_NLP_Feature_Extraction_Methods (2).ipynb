{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZntGNt8jXBgV"
   },
   "source": [
    "**Article on the subject** = https://medium.com/@hckecommerce/essential-nlp-feature-extraction-methods-1ff7cb4dc9f1\n",
    "\n",
    "# **Essential_NLP_Feature_Extraction_Methods.ipynb**\n",
    "\n",
    "NLP feature extraction methods are techniques used to convert raw text data into numerical representations that can be processed by machine learning models. These methods aim to capture the meaningful information and patterns in text data.\n",
    "\n",
    "**Here are some essential NLP feature extraction methods:**\n",
    "\n",
    "\n",
    "1.   Label Encoding\n",
    "2.   One Hot Encoding\n",
    "3.   Count Vectorization\n",
    "  * TF-IDF Vectorizer  \n",
    "  * Bag Of Words (BOW)\n",
    "\n",
    "4.      Word Embedding\n",
    "  *   Word2Vec\n",
    "  *   GloVe\n",
    "  *   FastText\n",
    "5. N-gram Features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJLcvPljYKA-"
   },
   "source": [
    "# **1 - Label Encoding**\n",
    "\n",
    "Label Encoding is a technique used to convert categorical variables(texts) into numerical representations. Each unique category is assigned a unique integer value.\n",
    "\n",
    "It can be quickly and easily integrated, but it does not understand the relationship between categories, for example, it does not recognize that nurses and doctors are closer to each other compared to others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "RX5xDB7yW96X",
    "outputId": "4f2f4049-7dfc-436e-b516-c09f9b25bf7b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Encoded_Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>teacher</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nurse</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>police</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doctor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category  Encoded_Labels\n",
       "0  teacher               3\n",
       "1    nurse               1\n",
       "2   police               2\n",
       "3   doctor               0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Example categorical data\n",
    "categories = ['teacher', 'nurse', 'police', 'doctor']\n",
    "\n",
    "# Initializing the LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fitting and transforming the categories\n",
    "encoded_labels = encoder.fit_transform(categories)\n",
    "\n",
    "# Creating a DataFrame\n",
    "df = pd.DataFrame({'Category': categories, 'Encoded_Labels': encoded_labels})\n",
    "\n",
    "# Printing the DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YcuVUyj1ZsCl"
   },
   "source": [
    "# **2 - One Hot Encoding**\n",
    "\n",
    "One Hot Encoding is a technique used to convert categorical variables into binary vectors. Each category is represented by a binary vector where only one element is \"hot\" (1) and the others are \"cold\" (0).\n",
    "\n",
    "If the number of categories is low, it is feasible to use One Hot Encoding to convert texts into numerical values.If the number of categories is large, adding a significant number of columns can lead to unnecessary data expansion, resulting in increased computational cost and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "gXutI4YHZsXl",
    "outputId": "20bfa1c5-2745-458d-c956-a82cab705de7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teacher</th>\n",
       "      <th>nurse</th>\n",
       "      <th>police</th>\n",
       "      <th>doctor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   teacher  nurse  police  doctor\n",
       "0        0      0       0       1\n",
       "1        0      1       0       0\n",
       "2        0      0       1       0\n",
       "3        1      0       0       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Example categorical data\n",
    "categories = ['teacher', 'nurse', 'police', 'doctor']\n",
    "\n",
    "# Convert categorical data into a DataFrame\n",
    "data = pd.DataFrame({'Category': categories})\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, dtype=int)\n",
    "\n",
    "# Fit and transform the categorical data\n",
    "encoded_data = encoder.fit_transform(data)\n",
    "\n",
    "# Convert the encoded data to a DataFrame\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=categories)\n",
    "\n",
    "# Print the encoded DataFrame\n",
    "encoded_df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XC13mq2QMpoI"
   },
   "source": [
    "# **3 - Count Vectorization**\n",
    "\n",
    "Count Vectorization is a technique used to convert text documents into numerical vectors based on the frequency of words in the documents. calculates according to the frequency of the word in the sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0D3Hl6PGMqRu"
   },
   "source": [
    "**a )  TF-IDF Vectorizer:**\n",
    "It combines the concepts of \"TF\" (Term Frequency) and \"IDF\" (Inverse Document Frequency)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "rC-1VG_nZvpt",
    "outputId": "673ae4ef-10a5-4140-9531-5f98c1402b2a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.469791</td>\n",
       "      <td>0.580286</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.687624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538648</td>\n",
       "      <td>0.281089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.511849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267104</td>\n",
       "      <td>0.511849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267104</td>\n",
       "      <td>0.511849</td>\n",
       "      <td>0.267104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.469791</td>\n",
       "      <td>0.580286</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        and  document     first        is       one    second       the  \\\n",
       "0  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
       "1  0.000000  0.687624  0.000000  0.281089  0.000000  0.538648  0.281089   \n",
       "2  0.511849  0.000000  0.000000  0.267104  0.511849  0.000000  0.267104   \n",
       "3  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
       "\n",
       "      third      this  \n",
       "0  0.000000  0.384085  \n",
       "1  0.000000  0.281089  \n",
       "2  0.511849  0.267104  \n",
       "3  0.000000  0.384085  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Example text data\n",
    "documents = [\"This is the first document.\",\n",
    "             \"This document is the second document.\",\n",
    "             \"And this is the third one.\",\n",
    "             \"Is this the first document?\"]\n",
    "\n",
    "# Convert text data into a DataFrame\n",
    "data = pd.DataFrame({'Text': documents})\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the text data\n",
    "tfidf_vectors = vectorizer.fit_transform(data['Text'])\n",
    "\n",
    "# Convert the TF-IDF vectors to a DataFrame\n",
    "tfidf_df = pd.DataFrame(tfidf_vectors.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Print the TF-IDF DataFrame\n",
    "tfidf_df.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rz9tQZzAU4A2"
   },
   "source": [
    "**a ) Bag Of Words (BOW):**\n",
    "\n",
    "It creates a vocabulary of unique words from the corpus and represents each document as a vector of word frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "PaM1EoWdP4FC",
    "outputId": "599292ba-0649-485c-ebeb-f5b895a61a37"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  document  first  is  one  second  the  third  this\n",
       "0    0         1      1   1    0       0    1      0     1\n",
       "1    0         2      0   1    0       1    1      0     1\n",
       "2    1         0      0   1    1       0    1      1     1\n",
       "3    0         1      1   1    0       0    1      0     1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Example text data\n",
    "documents = [\"This is the first document.\",\n",
    "             \"This document is the second document.\",\n",
    "             \"And this is the third one.\",\n",
    "             \"Is this the first document?\"]\n",
    "\n",
    "# Convert text data into a DataFrame\n",
    "data = pd.DataFrame({'Text': documents})\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the text data\n",
    "bow_vectors = vectorizer.fit_transform(data['Text'])\n",
    "\n",
    "# Convert the BOW vectors to a DataFrame\n",
    "bow_df = pd.DataFrame(bow_vectors.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Print the BOW DataFrame\n",
    "bow_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-S_76AnjSAI3"
   },
   "source": [
    "# **4 ) Word Embedding**\n",
    "\n",
    "Word Embedding is a technique in NLP that represents words as dense vectors in a high-dimensional space. It captures semantic meaning and word relationships, allowing for better understanding and processing of natural language. Word embeddings are learned from large text data using neural network models and provide dense representations that improve NLP model performance compared to sparse representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cz6My_2aSJyW"
   },
   "source": [
    "**a ) Word2Vec:**\n",
    "\n",
    "It is a neural network-based model that learns continuous vector representations (embeddings) of words from large text corpora. These embeddings capture semantic and syntactic relationships between words, allowing for more meaningful and context-aware word representations.\n",
    "\n",
    "**- CBOW (Continuous Bag of Words)**: predicts the target word based on the surrounding context words. Given the context words, CBOW tries to predict the target word in the center.\n",
    "\n",
    "**- Skip-gram**: predicts the surrounding context words given a target word. Given a target word in the center, Skip-gram aims to predict the context words that typically appear around it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3jlcmfg9alN"
   },
   "source": [
    "**- CBOW (Continuous Bag of Words)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "m5RFjfadU5w2",
    "outputId": "2402b088-b28c-4115-f404-bf4485ac7223"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>-0.010725</td>\n",
       "      <td>0.004729</td>\n",
       "      <td>0.102067</td>\n",
       "      <td>0.180185</td>\n",
       "      <td>-0.186059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vitamins</th>\n",
       "      <td>-0.142336</td>\n",
       "      <td>0.129177</td>\n",
       "      <td>0.179460</td>\n",
       "      <td>-0.100309</td>\n",
       "      <td>-0.075267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>provide</th>\n",
       "      <td>0.147610</td>\n",
       "      <td>-0.030669</td>\n",
       "      <td>-0.090732</td>\n",
       "      <td>0.131081</td>\n",
       "      <td>-0.097203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fruits</th>\n",
       "      <td>-0.036320</td>\n",
       "      <td>0.057532</td>\n",
       "      <td>0.019837</td>\n",
       "      <td>-0.165704</td>\n",
       "      <td>-0.188976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delicious</th>\n",
       "      <td>0.146235</td>\n",
       "      <td>0.101405</td>\n",
       "      <td>0.135154</td>\n",
       "      <td>0.015257</td>\n",
       "      <td>0.127018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>are</th>\n",
       "      <td>-0.068107</td>\n",
       "      <td>-0.018928</td>\n",
       "      <td>0.115371</td>\n",
       "      <td>-0.150433</td>\n",
       "      <td>-0.078722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apples</th>\n",
       "      <td>-0.150232</td>\n",
       "      <td>-0.018601</td>\n",
       "      <td>0.190762</td>\n",
       "      <td>-0.146383</td>\n",
       "      <td>-0.046675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fruits</th>\n",
       "      <td>-0.038755</td>\n",
       "      <td>0.161549</td>\n",
       "      <td>-0.118618</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>-0.095075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eating</th>\n",
       "      <td>-0.192071</td>\n",
       "      <td>0.100146</td>\n",
       "      <td>-0.175192</td>\n",
       "      <td>-0.087837</td>\n",
       "      <td>-0.000702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enjoy</th>\n",
       "      <td>-0.005924</td>\n",
       "      <td>-0.153225</td>\n",
       "      <td>0.192295</td>\n",
       "      <td>0.099641</td>\n",
       "      <td>0.184663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apples</th>\n",
       "      <td>-0.163158</td>\n",
       "      <td>0.089916</td>\n",
       "      <td>-0.082742</td>\n",
       "      <td>0.016491</td>\n",
       "      <td>0.169972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>-0.089244</td>\n",
       "      <td>0.090350</td>\n",
       "      <td>-0.135739</td>\n",
       "      <td>-0.070970</td>\n",
       "      <td>0.187970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1         2         3         4\n",
       "I         -0.010725  0.004729  0.102067  0.180185 -0.186059\n",
       "vitamins  -0.142336  0.129177  0.179460 -0.100309 -0.075267\n",
       "provide    0.147610 -0.030669 -0.090732  0.131081 -0.097203\n",
       "Fruits    -0.036320  0.057532  0.019837 -0.165704 -0.188976\n",
       "delicious  0.146235  0.101405  0.135154  0.015257  0.127018\n",
       "are       -0.068107 -0.018928  0.115371 -0.150433 -0.078722\n",
       "Apples    -0.150232 -0.018601  0.190762 -0.146383 -0.046675\n",
       "fruits    -0.038755  0.161549 -0.118618  0.000903 -0.095075\n",
       "eating    -0.192071  0.100146 -0.175192 -0.087837 -0.000702\n",
       "enjoy     -0.005924 -0.153225  0.192295  0.099641  0.184663\n",
       "apples    -0.163158  0.089916 -0.082742  0.016491  0.169972\n",
       "like      -0.089244  0.090350 -0.135739 -0.070970  0.187970"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CBOW (Continuous Bag of Words)\n",
    "\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Training data\n",
    "sentences = [[\"I\", \"like\", \"apples\"],\n",
    "             [\"I\", \"enjoy\", \"eating\", \"fruits\"],\n",
    "             [\"Apples\", \"are\", \"delicious\"],\n",
    "             [\"Fruits\", \"provide\", \"vitamins\"]]\n",
    "\n",
    "# Training the CBOW model with sg=0\n",
    "model_cbow_sg0 = Word2Vec(sentences, min_count=1, window=3, sg=0,vector_size= 5)\n",
    "\n",
    "# Accessing word vectors for CBOW (sg=0)\n",
    "word_vectors_sg0 = model_cbow_sg0.wv\n",
    "\n",
    "# Creating a DataFrame for word vectors with CBOW (sg=0)\n",
    "word_vectors_df_sg0 = pd.DataFrame(word_vectors_sg0.vectors, index=word_vectors_sg0.index_to_key)\n",
    "\n",
    "\n",
    "# Displaying the word vectors DataFrame\n",
    "word_vectors_df_sg0.head(15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOniG4IE9Ztu"
   },
   "source": [
    "**Skip-gram**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "b2b5n51n9Zks",
    "outputId": "93924ddd-efec-4d7c-c336-59e42404b6c4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>-0.010725</td>\n",
       "      <td>0.004729</td>\n",
       "      <td>0.102067</td>\n",
       "      <td>0.180185</td>\n",
       "      <td>-0.186059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vitamins</th>\n",
       "      <td>-0.142336</td>\n",
       "      <td>0.129177</td>\n",
       "      <td>0.179460</td>\n",
       "      <td>-0.100309</td>\n",
       "      <td>-0.075267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>provide</th>\n",
       "      <td>0.147610</td>\n",
       "      <td>-0.030669</td>\n",
       "      <td>-0.090732</td>\n",
       "      <td>0.131081</td>\n",
       "      <td>-0.097203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fruits</th>\n",
       "      <td>-0.036320</td>\n",
       "      <td>0.057532</td>\n",
       "      <td>0.019837</td>\n",
       "      <td>-0.165704</td>\n",
       "      <td>-0.188976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delicious</th>\n",
       "      <td>0.146235</td>\n",
       "      <td>0.101405</td>\n",
       "      <td>0.135154</td>\n",
       "      <td>0.015257</td>\n",
       "      <td>0.127018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>are</th>\n",
       "      <td>-0.068107</td>\n",
       "      <td>-0.018928</td>\n",
       "      <td>0.115371</td>\n",
       "      <td>-0.150433</td>\n",
       "      <td>-0.078722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apples</th>\n",
       "      <td>-0.150232</td>\n",
       "      <td>-0.018601</td>\n",
       "      <td>0.190762</td>\n",
       "      <td>-0.146383</td>\n",
       "      <td>-0.046675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fruits</th>\n",
       "      <td>-0.038755</td>\n",
       "      <td>0.161549</td>\n",
       "      <td>-0.118618</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>-0.095075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eating</th>\n",
       "      <td>-0.192071</td>\n",
       "      <td>0.100146</td>\n",
       "      <td>-0.175192</td>\n",
       "      <td>-0.087837</td>\n",
       "      <td>-0.000702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enjoy</th>\n",
       "      <td>-0.005924</td>\n",
       "      <td>-0.153225</td>\n",
       "      <td>0.192295</td>\n",
       "      <td>0.099641</td>\n",
       "      <td>0.184663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apples</th>\n",
       "      <td>-0.163158</td>\n",
       "      <td>0.089916</td>\n",
       "      <td>-0.082742</td>\n",
       "      <td>0.016491</td>\n",
       "      <td>0.169972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>-0.089244</td>\n",
       "      <td>0.090350</td>\n",
       "      <td>-0.135739</td>\n",
       "      <td>-0.070970</td>\n",
       "      <td>0.187970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1         2         3         4\n",
       "I         -0.010725  0.004729  0.102067  0.180185 -0.186059\n",
       "vitamins  -0.142336  0.129177  0.179460 -0.100309 -0.075267\n",
       "provide    0.147610 -0.030669 -0.090732  0.131081 -0.097203\n",
       "Fruits    -0.036320  0.057532  0.019837 -0.165704 -0.188976\n",
       "delicious  0.146235  0.101405  0.135154  0.015257  0.127018\n",
       "are       -0.068107 -0.018928  0.115371 -0.150433 -0.078722\n",
       "Apples    -0.150232 -0.018601  0.190762 -0.146383 -0.046675\n",
       "fruits    -0.038755  0.161549 -0.118618  0.000903 -0.095075\n",
       "eating    -0.192071  0.100146 -0.175192 -0.087837 -0.000702\n",
       "enjoy     -0.005924 -0.153225  0.192295  0.099641  0.184663\n",
       "apples    -0.163158  0.089916 -0.082742  0.016491  0.169972\n",
       "like      -0.089244  0.090350 -0.135739 -0.070970  0.187970"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Skip-gram\n",
    "\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Training data\n",
    "sentences = [[\"I\", \"like\", \"apples\"],\n",
    "             [\"I\", \"enjoy\", \"eating\", \"fruits\"],\n",
    "             [\"Apples\", \"are\", \"delicious\"],\n",
    "             [\"Fruits\", \"provide\", \"vitamins\"]]\n",
    "\n",
    "# Training the Skip-gram model with sg=1\n",
    "model_skip_gram_sg1 = Word2Vec(sentences, min_count=1, window=3, sg=1,vector_size=5)\n",
    "\n",
    "# Accessing word vectors for Skip-gram (sg=1)\n",
    "word_vectors_sg1 = model_skip_gram_sg1.wv\n",
    "\n",
    "# Creating a DataFrame for word vectors with Skip-gram (sg=1)\n",
    "word_vectors_df_sg1 = pd.DataFrame(word_vectors_sg1.vectors, index=word_vectors_sg1.index_to_key)\n",
    "\n",
    "# Displaying the word vectors DataFrame\n",
    "word_vectors_df_sg1.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cx8gpuNoJRNA"
   },
   "source": [
    "**b  )  GloVe:**\n",
    "\n",
    "GloVe stands for Global Vectors for Word Representation. It is an unsupervised learning algorithm that aims to generate word embeddings by capturing global word co-occurrence patterns in a corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NHHAuOg1OYFf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "words = ['apple', 'orange', 'banana', 'grape']\n",
    "vectors = [\n",
    "    [0.1, 0.2, 0.3, 0.4],\n",
    "    [0.5, 0.6, 0.7, 0.8],\n",
    "    [0.9, 1.0, 1.1, 1.2],\n",
    "    [1.3, 1.4, 1.5, 1.6]\n",
    "]\n",
    "\n",
    "glove_file = 'glove_file.txt'\n",
    "with open(glove_file, 'w', encoding='utf-8') as f:\n",
    "    for word, vector in zip(words, vectors):\n",
    "        vector_str = ' '.join(str(num) for num in vector)\n",
    "        f.write(f\"{word} {vector_str}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "FU1NOZagYLRm",
    "outputId": "ff9369ad-759e-4774-d288-85e45a961890"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-b26d9a01-292f-45cc-898e-fe92b346ea5e\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>apple</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orange</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>banana</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grape</th>\n",
       "      <td>1.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b26d9a01-292f-45cc-898e-fe92b346ea5e')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-b26d9a01-292f-45cc-898e-fe92b346ea5e button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-b26d9a01-292f-45cc-898e-fe92b346ea5e');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "          1    2    3    4\n",
       "0                         \n",
       "apple   0.1  0.2  0.3  0.4\n",
       "orange  0.5  0.6  0.7  0.8\n",
       "banana  0.9  1.0  1.1  1.2\n",
       "grape   1.3  1.4  1.5  1.6"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Load pre-trained GloVe embeddings\n",
    "glove_file = 'glove_file.txt'  # Path to the GloVe file\n",
    "# Reading the GloVe file\n",
    "word_vectors_df = pd.read_csv(glove_file, sep=' ', header=None, index_col=0, quoting=3)\n",
    "\n",
    "\n",
    "# Displaying the word vectors DataFrame\n",
    "word_vectors_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0CG41HwKeJJ"
   },
   "source": [
    "**c ) FastText**\n",
    "\n",
    "It learns word embeddings using the Skip-gram or Continuous Bag-of-Words (CBOW) architecture, making it effective for various natural language processing tasks. FastText is particularly useful for languages with rich morphology and large-scale datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p-SMGWLrKeho",
    "outputId": "a7da8fc1-ac28-4e94-94cd-53cd4b785d25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'apples' and 'fruits': 0.5611198\n",
      "Word analogy for 'eating' and 'fruits' - 'apples': [('enjoy', 0.09406167268753052), ('I', -0.022638631984591484), ('like', -0.06936056911945343)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import FastText\n",
    "\n",
    "# Training data\n",
    "sentences = [[\"I\", \"like\", \"apples\"],\n",
    "             [\"I\", \"enjoy\", \"eating\", \"fruits\"]]\n",
    "\n",
    "# Training the FastText model\n",
    "model_fasttext = FastText(sentences, min_count=1, window=5, vector_size=100)\n",
    "\n",
    "# Accessing word vectors\n",
    "word_vectors = model_fasttext.wv\n",
    "\n",
    "# Creating a DataFrame for word vectors\n",
    "word_vectors_df = pd.DataFrame(word_vectors.vectors, index=word_vectors.index_to_key)\n",
    "\n",
    "# Displaying the word vectors DataFrame\n",
    "word_vectors_df.head(10)\n",
    "\n",
    "similarity = model_fasttext.wv.similarity(\"apples\", \"fruits\")\n",
    "print(\"Similarity between 'apples' and 'fruits':\", similarity)\n",
    "\n",
    "\n",
    "analogies = model_fasttext.wv.most_similar(positive=[\"eating\", \"fruits\"], negative=[\"apples\"])\n",
    "print(\"Word analogy for 'eating' and 'fruits' - 'apples':\", analogies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_8pGtzZpkHTA"
   },
   "outputs": [],
   "source": [
    "import fasttext.util\n",
    "fasttext.util.download_model('en', if_exists='ignore')  # English\n",
    "ft = fasttext.load_model('cc.en.300.bin')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W2ZTxWCXR3O2"
   },
   "source": [
    "# **5 ) N-gram features**\n",
    "\n",
    "N-gram features are contiguous sequences of n words in a text document. They capture the contextual information and relationships between words, considering not just individual words but also the groups of words they form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "-litXeWQYLft",
    "outputId": "8b3c2204-af97-419e-ba15-af28d191589f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and this</th>\n",
       "      <th>and this is</th>\n",
       "      <th>and this is the</th>\n",
       "      <th>document is</th>\n",
       "      <th>document is the</th>\n",
       "      <th>document is the second</th>\n",
       "      <th>first document</th>\n",
       "      <th>is the</th>\n",
       "      <th>is the first</th>\n",
       "      <th>is the first document</th>\n",
       "      <th>...</th>\n",
       "      <th>this document</th>\n",
       "      <th>this document is</th>\n",
       "      <th>this document is the</th>\n",
       "      <th>this is</th>\n",
       "      <th>this is the</th>\n",
       "      <th>this is the first</th>\n",
       "      <th>this is the third</th>\n",
       "      <th>this the</th>\n",
       "      <th>this the first</th>\n",
       "      <th>this the first document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   and this  and this is  and this is the  document is  document is the  \\\n",
       "0         0            0                0            0                0   \n",
       "1         0            0                0            1                1   \n",
       "2         1            1                1            0                0   \n",
       "3         0            0                0            0                0   \n",
       "\n",
       "   document is the second  first document  is the  is the first  \\\n",
       "0                       0               1       1             1   \n",
       "1                       1               0       1             0   \n",
       "2                       0               0       1             0   \n",
       "3                       0               1       0             0   \n",
       "\n",
       "   is the first document  ...  this document  this document is  \\\n",
       "0                      1  ...              0                 0   \n",
       "1                      0  ...              1                 1   \n",
       "2                      0  ...              0                 0   \n",
       "3                      0  ...              0                 0   \n",
       "\n",
       "   this document is the  this is  this is the  this is the first  \\\n",
       "0                     0        1            1                  1   \n",
       "1                     1        0            0                  0   \n",
       "2                     0        1            1                  0   \n",
       "3                     0        0            0                  0   \n",
       "\n",
       "   this is the third  this the  this the first  this the first document  \n",
       "0                  0         0               0                        0  \n",
       "1                  0         0               0                        0  \n",
       "2                  1         0               0                        0  \n",
       "3                  0         1               1                        1  \n",
       "\n",
       "[4 rows x 35 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Example text data\n",
    "documents = [\"This is the first document.\",\n",
    "             \"This document is the second document.\",\n",
    "             \"And this is the third one.\",\n",
    "             \"Is this the first document?\"]\n",
    "\n",
    "# Convert text data into a DataFrame\n",
    "data = pd.DataFrame({'Text': documents})\n",
    "\n",
    "# Initialize the CountVectorizer with desired n-gram range\n",
    "ngram_vectorizer = CountVectorizer(ngram_range=(2,4))\n",
    "\n",
    "# Fit and transform the text data\n",
    "ngram_vectors = ngram_vectorizer.fit_transform(data['Text'])\n",
    "\n",
    "# Convert the N-gram vectors to a DataFrame\n",
    "ngram_df = pd.DataFrame(ngram_vectors.toarray(), columns=ngram_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Print the N-gram DataFrame\n",
    "ngram_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
